
# ğŸ“º Netflix Data Platform Project

This project demonstrates an end-to-end data engineering pipeline for a Netflix-like application using **dbt**, **BigQuery**, and **modular data modeling** principles. It follows a layered architecture to organize data across raw, staging, marts, and product layers.

---

## ğŸ—ï¸ Project Structure
â”œâ”€â”€ data/ â”‚ 
â””â”€â”€ seeds/ â”‚ 
    â”œâ”€â”€ users.csv â”‚ 
    â”œâ”€â”€ profiles.csv â”‚ 
    â”œâ”€â”€ contents.csv â”‚ 
    â”œâ”€â”€ genres.csv â”‚ 
    â”œâ”€â”€ content_genre.csv â”‚ 
    â”œâ”€â”€ devices.csv â”‚ 
    â””â”€â”€ viewing_sessions.csv 
â”œâ”€â”€ models/ â”‚ 
    â”œâ”€â”€ raw/ â”‚ 
    â”œâ”€â”€ staging/ â”‚ 
    â””â”€â”€ marts/ 
    â”œâ”€â”€ snapshots/ 
    â”œâ”€â”€ tests/ 
â”œâ”€â”€ dbt_project.yml 
â”œâ”€â”€ README.md 


---

## ğŸ§± Layers

### ğŸ”¹ RAW Layer (Seeded from CSVs)
- `users`, `profiles`, `contents`, `genres`, `content_genre`, `devices`, `viewing_sessions`

### ğŸ”¸ STAGING Layer
- Cleaned and renamed tables using `ref()` to map raw tables
- Examples: `stg_users`, `stg_profiles`, `stg_contents`, `stg_viewing_sessions`

### ğŸŸ© MARTS Layer
- **Dimensions**: `dim_users`, `dim_profiles`, `dim_contents`
- **Facts**: `fact_viewing_sessions`

---

## ğŸ“Š Data Flow

1. **Seed** raw CSV data into BigQuery via `dbt seed`
2. **Transform** with staging models (`dbt run --select staging`)
3. **Build analytics-ready tables** in marts (`dbt run --select marts`)
4. Optional: Add **tests**, **docs**, and **snapshots**

---

## ğŸš€ How to Run

```bash
# Install dependencies
dbt deps

# Seed the raw data
dbt seed

# Run staging + marts
dbt run

# Test your models
dbt test


